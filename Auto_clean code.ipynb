{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce242e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ngram'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mngram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NGram\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdateutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchart_studio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plotly \u001b[38;5;28;01mas\u001b[39;00m py\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ngram'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import itertools\n",
    "from ngram import NGram\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from chart_studio import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(colorscale='plotly', world_readable=True)\n",
    "\n",
    "# Extra options\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_columns = 25\n",
    "\n",
    "# Show all code cells outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import os\n",
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy import stats\n",
    "\n",
    "import missingno as msno\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a464584",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = input(\"filepath: \")\n",
    "delimiter = input(\"delimiter: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1245867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filepath, sep\u001b[38;5;241m=\u001b[39mdelimiter)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auto'"
     ]
    }
   ],
   "source": [
    "if delimiter == '':\n",
    "    df = pd.read_csv(filepath)\n",
    "else:\n",
    "    df = pd.read_csv(filepath, sep=delimiter)\n",
    "df[\"id\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "230237ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCharacteristics of Input Dataset\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCharacteristics of Input Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of fields/characteristics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of data entries:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' + \"Characteristics of Input Dataset\" + '\\033[0m')\n",
    "print(\"Number of fields/characteristics:\", df.shape[1])\n",
    "print(\"Number of data entries:\", df.shape[0])\n",
    "print(\"-----------------------------------------------\")\n",
    "print('\\033[4m' + \"Number of missing entries per column:\" + '\\033[0m')\n",
    "print(df.isnull().sum())\n",
    "print(\"-----------------------------------------------\")\n",
    "print('\\033[4m' + \"Datatype of each column:\"+ '\\033[0m')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1d60a88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwidgets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interact, interact_manual\n\u001b[0;32m      4\u001b[0m \u001b[38;5;129m@interact\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df[column]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "@interact\n",
    "def describe(column=list(df.columns)):\n",
    "    print(df[column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8089fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "\u001b[4mMost Common Data Entries By Column\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[4m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMost Common Data Entries By Column\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m:\n\u001b[0;32m      4\u001b[0m     unique_vals \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_vals) \u001b[38;5;241m<\u001b[39m (df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------\")\n",
    "print('\\033[4m' + \"Most Common Data Entries By Column\" + '\\033[0m')\n",
    "for column in df:\n",
    "    unique_vals = df[column].unique()\n",
    "    if len(unique_vals) < (df.shape[0]/10):\n",
    "        print('\\n'+'\\033[1m' + '\\033[4m' + \"Column: \" + column + '\\033[0m')\n",
    "        print(df[column].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7291c8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m numerical_columns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (df[column]\u001b[38;5;241m.\u001b[39mdtypes \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m df[column]\u001b[38;5;241m.\u001b[39mdtypes \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      5\u001b[0m         numerical_columns\u001b[38;5;241m.\u001b[39mappend(column)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "numerical_columns = []\n",
    "for column in df:\n",
    "    if (df[column].dtypes == \"int64\" or df[column].dtypes == \"float64\"):\n",
    "        numerical_columns.append(column)\n",
    "        count += 1\n",
    "\n",
    "fig, axes =  plt.subplots(math.ceil(count/2),2, figsize=(15,5 * math.ceil(count/2)))\n",
    "i=0\n",
    "j=0\n",
    "for col in numerical_columns:\n",
    "    #a[i][j].set_xlabel(col) , \n",
    "    df[col].hist(ax=axes[i][j])\n",
    "    axes[i][j].set_title('Distribution of ' + col)\n",
    "    if j == 1:\n",
    "        j = 0\n",
    "        i += 1\n",
    "    else:\n",
    "        j += 1\n",
    "plt.suptitle(\"Distribution of the Numerical Columns of Dataset\", fontsize=20)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.98]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28dd08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def duplicate_clean (col):\n",
    "    if (not df[col].is_unique):\n",
    "        print(\"\\n The '\" + col + \"' column contains duplicates, what would you like do? (pick one of the following options)\")\n",
    "        print(\"(1) Keep all duplicates\")\n",
    "        print(\"(2) Drop all duplicates that are identical across all columns\")\n",
    "        print(\"(3) Drop all duplicates of this column\")\n",
    "        time.sleep(0.05)\n",
    "        dup_option = input('\\033[1m' + \"Input the option number: \" + '\\033[0m')\n",
    "        if dup_option == \"1\" or dup_option == \"(1)\":\n",
    "            return\n",
    "        elif dup_option == \"2\" or dup_option == \"(2)\":\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            return\n",
    "        elif dup_option == \"3\" or dup_option == \"(3)\":\n",
    "            print(\"Please specify 'first', 'last', or 'none' to indicate which duplicate, if any, should be kept.\")\n",
    "            time.sleep(0.05)\n",
    "            drop_pref = input('\\033[1m' + \"Input drop preference: \" + '\\033[0m')\n",
    "            if drop_pref == \"none\":\n",
    "                df.drop_duplicates([col], keep=False, inplace=True)\n",
    "                return\n",
    "            else:\n",
    "                df.drop_duplicates([col], keep=drop_pref, inplace=True)\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8b15abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the groupings of a certain column, note that the data must be non-numerical\n",
    "def clean_non_numerical (col):\n",
    "    \n",
    "    # for non-numerical columns with unqiue values more than half the number of rows check for duplicates\n",
    "    unique_vals = df[col].unique()\n",
    "    if (len(unique_vals) > 30):\n",
    "        return duplicate_clean(col)\n",
    "    \n",
    "    # do not consider date columns\n",
    "    def is_date(string):\n",
    "        try: \n",
    "            parse(string)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    \n",
    "    # check if date is valid\n",
    "    for i, row_value in df[col].head(5).iteritems():\n",
    "        if is_date(df[col][i]):\n",
    "            return\n",
    "    \n",
    "    # check for abbreviated nation names\n",
    "    if ('country' in col) or ('COUNTRY' in col) or ('Country' in col):\n",
    "        invalid_df_us = df[(df[col] == 'United States') | (df[col] == 'United States of America') | (df[col] == 'USA') | (df[col] == 'usa') | (df[col] == 'us')]\n",
    "        if invalid_df_us.shape[0] > 0:\n",
    "            print(\"There are \" + str(invalid_df_us.shape[0])+ \" alternate references to the US. These age entries will be all be set to US.\")\n",
    "            df.loc[(df[col] == 'United States') | (df[col] == 'United States of America') | (df[col] == 'USA') | (df[col] == 'usa') | (df[col] == 'us'), [col]] = 'US'\n",
    "        invalid_df_uk = df[(df[col] == 'United Kingdom') | (df[col] == 'uk')]\n",
    "        if invalid_df_us.shape[0] > 0:\n",
    "            print(\"There are \" + str(invalid_df_us.shape[0])+ \" alternate references to the UK. These age entries will be all be set to UK.\")\n",
    "            df.loc[(df[col] == 'United Kingdom') | (df[col] == 'uk'), [col]] = 'UK'\n",
    "        \n",
    "    # establish starting point\n",
    "    unique_vals = ['None' if x is np.nan else x for x in unique_vals]\n",
    "    unique_vals = ['None' if v is None else v for v in unique_vals]\n",
    "    print(\"\\n Initial set of unqiue entries in '\" + col + \"' column: \"+ '\\033[1m' + \", \".join(unique_vals) + '\\033[0m')\n",
    "    \n",
    "    # remove leading and trailing blank spaces\n",
    "    df[col] = df[col].replace(r\"^ +| +$\", r\"\", regex=True)\n",
    "    \n",
    "    # standardize all text to \"title case\"\n",
    "    def title_case(string):\n",
    "        if pd.isnull(string):\n",
    "            return None\n",
    "        return re.sub(r\"[A-Za-z]+('[A-Za-z]+)?\", lambda word: word.group(0).capitalize(), string)\n",
    "    df[col] = df[col].apply(lambda x: title_case(x))\n",
    "    \n",
    "    # compare strings of all titles to see if they can be merged\n",
    "    def ngram_compare(a,b):\n",
    "        if NGram.compare(a,b) > 0.4:\n",
    "            print(\"\\n\", a,b)\n",
    "            time.sleep(0.05)\n",
    "            combine = input(\"Would you consider the above two entries the same? (yes/no) \")\n",
    "            if combine == 'yes' or combine == 'y':\n",
    "                while True:\n",
    "                    time.sleep(0.05)\n",
    "                    combine_to = input(\"To which entry would you like the text to be merged to? (input field name)\")\n",
    "                    if combine_to == a:\n",
    "                        df[col] = df[col].replace({b: a}, regex=True)\n",
    "                        return\n",
    "                    elif combine_to == b:\n",
    "                        df[col] = df[col].replace({a: b}, regex=True)\n",
    "                        return\n",
    "                    else:\n",
    "                        continue\n",
    "    unique_vals = df[col].unique()\n",
    "    for pair in itertools.combinations(unique_vals, r=2):\n",
    "        ngram_compare(*pair)\n",
    "    print(\"\\n\")\n",
    "    # show end point\n",
    "    unique_vals = df[col].unique()\n",
    "    unique_vals = ['None' if v is None else v for v in unique_vals]\n",
    "    print(\"Final set of unqiue entries in '\" + col + \"' column: \"+ '\\033[1m' + \", \".join(unique_vals) + '\\033[0m' +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91f29a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(df[column]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m      6\u001b[0m         clean_non_numerical (column)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for column in df:\n",
    "    if(df[column].dtype == object):\n",
    "        clean_non_numerical (column)\n",
    "print(\"\\n\")\n",
    "print('\\033[1m' + \"** Non-Numerical Data Cleaning Complete! **\" + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca470688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numerical (col, df):\n",
    "    \n",
    "    # remove outliers\n",
    "    print( \"Input the number of standard deviations from the mean you are willing to include for the '\" + '\\033[1m' + col + '\\033[0m' + \"' column.\")\n",
    "    print(\"If you wish to keep outliers for this column, please write all.\")\n",
    "    time.sleep(0.05)\n",
    "    sd = input(\"Input standard deviations: \")\n",
    "    if sd != 'all':\n",
    "        cols_outside_sd = df\n",
    "        cols_outside_sd = cols_outside_sd[(np.abs(stats.zscore(df[col])) > int(sd))]\n",
    "        print(\"There are \" +'\\033[1m'+ str(cols_outside_sd.shape[0]) + '\\033[0m' + \" rows that are outliers accoridng to your standard deviation value.\")\n",
    "        if cols_outside_sd.shape[0] > 0:\n",
    "            print(\"These rows will be deleted from the original dataset.\\n\")\n",
    "            df = df[(np.abs(stats.zscore(df[col])) < int(sd))]\n",
    "        else:\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # remove duplicates\n",
    "    duplicate_clean(col)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # check if zip code is valid\n",
    "    if ('zip' in col) or ('ZIP' in col):\n",
    "        invalid_df = df[(df[col] < 1) | (df[col] > 99950)]\n",
    "        if invalid_df.shape[0] > 0:\n",
    "            print(\"There are \" + str(invalid_df.shape[0])+ \" invalid ZIP codes in your data. These ZIP entries will be set to null for now.\\n\")\n",
    "            #df.drop(df[(df[col] < 1) | (df[col] > 99950)].index, inplace=True)\n",
    "            df.loc[(df[col] < 1) | (df[col] > 99950), [col]] = np.nan\n",
    "\n",
    "    \n",
    "    # check if age is valid\n",
    "    if ('age' in col) or ('AGE' in col):\n",
    "        invalid_df = df[(df[col] < 0) | (df[col] > 120)]\n",
    "        if invalid_df.shape[0] > 0:\n",
    "            print(\"There are \" + str(invalid_df.shape[0])+ \" invalid ages in your data. These age entries will be set to null for now.\\n\")\n",
    "            df.loc[(df[col] < 0) | (df[col] > 120), [col]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1fe087c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(df[column]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m df[column]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m         clean_numerical (column, df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for column in df:\n",
    "    if(df[column].dtype == 'int64' or df[column].dtype == 'float64'):\n",
    "        clean_numerical (column, df)\n",
    "\n",
    "# Smart Duplication Removal\n",
    "print(\"'Smart' duplication deletion: look at the numerical columns of duplicated rows and only delete duplicates that are 'similar'\")\n",
    "confirm = input(\"Confirm if you would like to run this duplicate deletion method: \")\n",
    "if confirm == \"yes\" or confirm == \"y\":\n",
    "    smart_dup = pd.DataFrame(1 - squareform(pdist(df.set_index('id'), lambda u,v: (u != v).mean())))\n",
    "    smart_dup.values[[np.arange(smart_dup.shape[0])]*2] = 0\n",
    "    smart_dup = smart_dup.mask(np.triu(np.ones(smart_dup.shape, dtype=np.bool_)))\n",
    "    duplicates = smart_dup[smart_dup > 0.8]\n",
    "    dup_list = np.stack(duplicates.notnull().values.nonzero()).T.tolist()\n",
    "    print('\\033[1m' + \"Below is the set duplicated rows that our algorithm found: \" + '\\033[0m')\n",
    "    print(\"Use the interactive toggle to compare the two 'similar' rows. Note that the duplicates will be deleted from the original dataframe.\")\n",
    "    for dup in dup_list:\n",
    "        display(df.iloc[[dup[0],dup[1]],:])\n",
    "    for dup in dup_list:\n",
    "        try:\n",
    "            df.drop(df.index[dup[0]], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "print('\\033[1m' + \"** Numerical Data Cleaning Complete! **\" + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f831bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVisualizing the Missing Data: Completeness of Dataset\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing the Missing Data: Completeness of Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m msno\u001b[38;5;241m.\u001b[39mbar(\u001b[43mdf\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' + \"Visualizing the Missing Data: Completeness of Dataset\" + '\\033[0m')\n",
    "msno.bar(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25e51c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVisualizing the Missing Data: Data Completion Patterns\u001b[0m\n",
      "Note: This is from a random sample of 100 entries.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing the Missing Data: Data Completion Patterns\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: This is from a random sample of 100 entries.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m msno\u001b[38;5;241m.\u001b[39mmatrix(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m100\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' + \"Visualizing the Missing Data: Data Completion Patterns\" + '\\033[0m')\n",
    "print(\"Note: This is from a random sample of 100 entries.\")\n",
    "msno.matrix(df.sample(100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14065889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVisualizing the Missing Data: Correlation Between Data\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing the Missing Data: Correlation Between Data\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m msno\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mdf\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' + \"Visualizing the Missing Data: Correlation Between Data\" + '\\033[0m')\n",
    "msno.heatmap(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "427aedf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(df[pd\u001b[38;5;241m.\u001b[39misnull(df[column])]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m missing entries in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df[pd\u001b[38;5;241m.\u001b[39misnull(df[column])]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for column in df:\n",
    "    print(\"There are \" + '\\033[1m' + str(df[pd.isnull(df[column])].shape[0]) + '\\033[0m' + \" missing entries in the '\" + column + \"' column.\")\n",
    "    if df[pd.isnull(df[column])].shape[0] > 0:\n",
    "        print(\"Pick one of the following options to handle these missing entries.\")\n",
    "        print(\"(1) Leave the missing entries as they are, so the missing values do not contribute to any computations.\")\n",
    "        print(\"(2) Drop the rows with a missing entry.\")\n",
    "        print(\"(3) Drop the entire column.\")\n",
    "        print(\"(4) Simple Imputation: Replace the missing data with a substituted value.\")\n",
    "        if (df[column].dtype == 'int64' or df[column].dtype == 'float64'):\n",
    "            print(\"(5) Advanced Imputation: Using Machine Learning to substitute missing data.\")\n",
    "        time.sleep(0.05)\n",
    "        del_option = input('\\033[1m' + \"Input the option number: \" + '\\033[0m')\n",
    "        if del_option == \"1\" or del_option == \"(1)\":\n",
    "            continue\n",
    "        elif del_option == \"2\" or del_option == \"(2)\":\n",
    "            df.dropna(subset=[column],how='any',inplace=True)\n",
    "        elif del_option == \"3\" or del_option == \"(3)\":\n",
    "            df.drop(columns=[column], inplace=True)\n",
    "        elif del_option == \"4\" or del_option == \"(4)\":\n",
    "            print(\"(a) Impute with a constant value.\")\n",
    "            print(\"(b) Impute with the most frequent value.\")\n",
    "            if (df[column].dtype == 'int64' or df[column].dtype == 'float64'):\n",
    "                print(\"(c) Impute with the mean value of the column.\")\n",
    "                print(\"(d) Impute with the median value of the column.\")\n",
    "            time.sleep(0.05)\n",
    "            imp_option = input('\\033[1m' + \"Input the letter for simple imputation: \" + '\\033[0m') \n",
    "            if imp_option == 'a' or imp_option == '(a)':\n",
    "                constant = input('\\033[1m' + \"Input the constant that you wish to substitute: \" + '\\033[0m') \n",
    "                if (df[column].dtype == 'int64' or df[column].dtype == 'float64'):\n",
    "                    mean_imputer = SimpleImputer(strategy='constant', fill_value=int(constant))\n",
    "                elif(df[column].dtype == 'object'):\n",
    "                    mean_imputer = SimpleImputer(strategy='constant', fill_value=constant)\n",
    "            elif imp_option == 'b' or imp_option == '(b)':\n",
    "                mean_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            elif imp_option == 'c' or imp_option == '(c)':\n",
    "                mean_imputer = SimpleImputer(strategy='mean')\n",
    "            elif imp_option == 'd' or imp_option == '(d)':\n",
    "                mean_imputer = SimpleImputer(strategy='median')\n",
    "            df[column] = mean_imputer.fit_transform(df[[column]]).ravel()\n",
    "        elif del_option == \"5\" or del_option == \"(5)\":\n",
    "            print(\"(a) Impute using the K-Nearest Neighbor Imputation. More details can be found here: https://scikit-learn.org/stable/modules/impute.html#nearest-neighbors-imputation\")\n",
    "            print(\"(b) Impute using Multivariate imputation by chained equations (MICE). More details can be found here: https://scikit-learn.org/stable/modules/impute.html#multivariate-feature-imputation\")\n",
    "            time.sleep(0.05)\n",
    "            imp_option = input('\\033[1m' + \"Input the letter for advanced imputation: \" + '\\033[0m')\n",
    "            if imp_option == 'a' or imp_option == '(a)':\n",
    "                knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "                df[column] = knn_imputer.fit_transform(df[[column]])\n",
    "            elif imp_option == 'b' or imp_option == '(b)':\n",
    "                mice_imputer = IterativeImputer()\n",
    "                df[column] = mice_imputer.fit_transform(df[[column]])\n",
    "    print(\"\\n\")\n",
    "print('\\033[1m' + \"** Missing Data Cleaning Complete! **\" + '\\033[0m') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8350a4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;129m@interact\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df[column]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "@interact\n",
    "def describe(column=list(df.columns)):\n",
    "    print(df[column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb684cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;129m@interact\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhist_plot\u001b[39m(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns),\n\u001b[0;32m      3\u001b[0m                  theme\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(cf\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mTHEMES\u001b[38;5;241m.\u001b[39mkeys()), \n\u001b[0;32m      4\u001b[0m                  colorscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(cf\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39m_scales_names\u001b[38;5;241m.\u001b[39mkeys())):\n\u001b[0;32m      6\u001b[0m     df[x]\u001b[38;5;241m.\u001b[39miplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m              title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistogram of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m             theme\u001b[38;5;241m=\u001b[39mtheme, colorscale\u001b[38;5;241m=\u001b[39mcolorscale)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "@interact\n",
    "def hist_plot(x=list(df.select_dtypes('number').columns),\n",
    "                 theme=list(cf.themes.THEMES.keys()), \n",
    "                 colorscale=list(cf.colors._scales_names.keys())):\n",
    "        \n",
    "    df[x].iplot(kind='hist',\n",
    "             title=f'Histogram of {x}',\n",
    "            theme=theme, colorscale=colorscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5bd282f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;129m@interact\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter_plot\u001b[39m(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns), \n\u001b[0;32m      3\u001b[0m                  y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mselect_dtypes(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns)[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m      4\u001b[0m                  theme\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(cf\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mTHEMES\u001b[38;5;241m.\u001b[39mkeys()), \n\u001b[0;32m      5\u001b[0m                  colorscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(cf\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39m_scales_names\u001b[38;5;241m.\u001b[39mkeys())):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m      7\u001b[0m     df\u001b[38;5;241m.\u001b[39miplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscatter\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarkers\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      8\u001b[0m              xTitle\u001b[38;5;241m=\u001b[39mx, yTitle\u001b[38;5;241m=\u001b[39my, \n\u001b[0;32m      9\u001b[0m              \u001b[38;5;66;03m#text='title',\u001b[39;00m\n\u001b[0;32m     10\u001b[0m              title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScatter Plot of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m against \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m             theme\u001b[38;5;241m=\u001b[39mtheme, colorscale\u001b[38;5;241m=\u001b[39mcolorscale)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "@interact\n",
    "def scatter_plot(x=list(df.select_dtypes('number').columns), \n",
    "                 y=list(df.select_dtypes('number').columns)[1:],\n",
    "                 theme=list(cf.themes.THEMES.keys()), \n",
    "                 colorscale=list(cf.colors._scales_names.keys())):\n",
    "    print(x)\n",
    "    df.iplot(kind='scatter', x=x, y=y, mode='markers', \n",
    "             xTitle=x, yTitle=y, \n",
    "             #text='title',\n",
    "             title=f'Scatter Plot of {y} against {x}',\n",
    "            theme=theme, colorscale=colorscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExport the Final Dataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' + \"Export the Final Dataset\" + '\\033[0m')\n",
    "time.sleep(0.05)\n",
    "filename = input(\"Input the filename of the export followed by the file extension: \")\n",
    "filename_spl = filename.split('.')\n",
    "if filename_spl[1] == 'csv':\n",
    "    df.to_csv(filename,index=False)\n",
    "elif filename_spl[1] == 'csv':\n",
    "    df.to_excel(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e84ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
